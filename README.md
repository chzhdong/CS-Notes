# LMSYS-Notes
为了便于之后的学习回顾，以及方便以后想进入大模型推理加速领域的同学们，我准备记录我自己在学习过程中所学习的资料、项目、源代码、阅读的论文等慢慢整理汇总。

希望这份笔记可以帮助同学们更快、更好地了解大模型推理优化领域的知识，快速成为一名优秀的工程师！

## Paper

### Survey

- [Challenges and Applications of Large Language Models](https://arxiv.org/abs/2307.10169)

### Architectrue

- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)

### Attention

- [FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness](https://arxiv.org/abs/2205.14135)
   - [笔记](./Paper/FlashAttention)

### Batching

- [Orca: A Distributed Serving System for Transformer-Based Generative Models](https://www.usenix.org/conference/osdi22/presentation/yu)

### Decoding

- [Accelerating Large Language Model Decoding with Speculative Sampling](https://arxiv.org/abs/2302.01318)

### Quantization

- [AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration](https://arxiv.org/abs/2306.00978)

### Serving

- [Llumnix: Dynamic Scheduling for Large Language Model Serving](https://arxiv.org/abs/2406.03243)
   - [笔记](./Paper/Llumnix)

## C++

### 参考

- [现代 C++ 教程: 高速上手 C++ 11/14/17/20](https://changkun.de/modern-cpp/)

- [An Introduction to Modern CMake — Modern CMake](https://cliutils.gitlab.io/modern-cmake/README.html)

## CUDA

### 参考

- [CUDA编程入门极简教程](https://zhuanlan.zhihu.com/p/34587739)

- [《CUDA C Programming Guide》导读](https://zhuanlan.zhihu.com/p/53773183)

## 其他

### 博客

- [LLM推理算法简述](https://zhuanlan.zhihu.com/p/685794495)
- [缓存与效果的极限拉扯：从MHA、MQA、GQA到MLA](https://kexue.fm/archives/10091)
